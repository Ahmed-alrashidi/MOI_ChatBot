ğŸ‡¸ğŸ‡¦ MOI Smart Assistant

An Advanced RAG-based Chatbot for Saudi Ministry of Interior Services

MOI Smart Assistant is a specialized AI chatbot designed to answer queries regarding Saudi Ministry of Interior (MOI) services, such as Passports (Jawazat), Civil Affairs (Ahwal), and Traffic (Muroor). It leverages ALLaM-7B (a premier Arabic LLM), Whisper for voice recognition, and a Hybrid RAG engine to provide accurate, context-aware responses.

âœ¨ Key Features

Hybrid RAG Engine: Combines Dense Vector Search (Embedding) with Keyword Search (BM25) for maximum retrieval accuracy.

Native Arabic Support: Powered by ALLaM-7B, optimized for Saudi dialect and formal Arabic.

Voice Interaction: Supports voice input using OpenAI's Whisper model.

Platform Agnostic: Runs seamlessly on Google Colab, HPC Clusters (IBEX), or local machines.

Smart Query Rewriting: Automatically translates and expands queries to find better matches in the database.

ğŸš€ Quick Start

Follow these steps to set up the project on any environment.

1. Clone the Repository

git clone [https://github.com/Ahmed-alrashidi/MOI_ChatBot.git](https://github.com/Ahmed-alrashidi/MOI_ChatBot.git)
cd MOI_ChatBot


2. One-Click Setup

We provide a setup script that automatically handles Python dependencies, system libraries (ffmpeg), and environment configuration.

bash setup.sh


ğŸ”‘ Authentication (Important)

To access the ALLaM-7B model, you need a valid Hugging Face Token.

Step 1: Get your Token

Go to your Hugging Face Settings.

Create a new token with Read permissions.

Copy the token (starts with hf_...).

Step 2: Add Token to the Project

ğŸ…°ï¸ Option A: Google Colab (Recommended)

On the left sidebar, click the Secrets (Key icon ğŸ”‘).

Add a new secret:

Name: HF_TOKEN

Value: Paste your token.

Toggle Notebook access to ON.

ğŸ…±ï¸ Option B: Local Machine / Terminal / IBEX

Open the .env file created by the setup script.

Paste your token inside:

HF_TOKEN=hf_your_token_here


Save the file.

â–¶ï¸ Usage

Once setup is complete and the token is added, launch the application:

python main.py


What happens next?

The system ingests the CSV data and builds the Vector Database (if not already built).

It loads the AI models (ALLaM & Whisper) onto the GPU.

It launches a Gradio Web Interface.

A Public URL will be displayed in the terminal (e.g., https://xxxx.gradio.live) which you can share or open on any device.

ğŸ“‚ Project Structure

The project follows a modular architecture for easy maintenance:

MOI_ChatBot/
â”œâ”€â”€ core/               # The AI Brain
â”‚   â”œâ”€â”€ model_loader.py # Handles loading LLMs & Embeddings (Singleton)
â”‚   â”œâ”€â”€ rag_pipeline.py # RAG Logic (Retrieval + Reranking + Generation)
â”‚   â””â”€â”€ vector_store.py # FAISS Database Management
â”‚
â”œâ”€â”€ data/               # Data Layer
â”‚   â”œâ”€â”€ Data_Master/    # Raw CSVs (Service Descriptions)
â”‚   â”œâ”€â”€ Data_chunks/    # Raw CSVs (Detailed chunks)
â”‚   â””â”€â”€ vector_db/      # Generated FAISS Index
â”‚
â”œâ”€â”€ ui/                 # Frontend
â”‚   â”œâ”€â”€ app.py          # Gradio Interface Logic
â”‚   â””â”€â”€ theme.py        # Custom CSS & Branding
â”‚
â”œâ”€â”€ utils/              # Utilities
â”‚   â”œâ”€â”€ logger.py       # Centralized Logging
â”‚   â””â”€â”€ text_utils.py   # Arabic Normalization & Cleaning
â”‚
â”œâ”€â”€ config.py           # Central Configuration (Paths & Hyperparameters)
â”œâ”€â”€ main.py             # Entry Point
â””â”€â”€ setup.sh            # Installation Script


ğŸ›  Hardware Requirements

GPU: NVIDIA A100, V100, or T4 (Min 16GB VRAM recommended).

RAM: 32GB+ System RAM.

Storage: At least 20GB free space for models.

Developed by Ahmed Alrashidi for the MOI Chatbot Project.