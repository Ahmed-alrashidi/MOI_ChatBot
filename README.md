# MOI Universal Assistant

> **An enterprise-grade AI conversational agent designed for the Ministry of Interior (MOI).**

This system utilizes the **Sovereign Saudi LLM (ALLaM-7B)** and a **Hybrid RAG architecture** to provide accurate, real-time assistance for Passport, Traffic, and Security services. It is strictly optimized for **NVIDIA A100** infrastructure.

---

## âœ¨ Key Features

### ğŸ§  Saudi-Native Intelligence
Powered by **ALLaM-7B-Instruct** to deeply understand local dialects, regulations, and cultural context.

### âš¡ A100 Optimized Architecture
Built with `bfloat16` precision and **Flash Attention 2** support for lightning-fast inference on High-Performance Computing (HPC/IBEX) clusters.

### ğŸ” Hybrid RAG Engine
Implements **Reciprocal Rank Fusion (RRF)** combining:
* **Semantic Search:** Dense retrieval via `BAAI/bge-m3` (Cosine Similarity).
* **Keyword Search:** Sparse retrieval via `BM25` for precise terminology matching.

### ğŸ—£ï¸ Multimodal Interface
* **Voice-to-Text:** `Whisper Large v3` for high-accuracy Arabic speech recognition.
* **Text-to-Speech:** Integrated `gTTS` with auto-cleanup logic for seamless audio responses.

### ğŸ›¡ï¸ Robust Data Pipeline
Advanced ETL with strict schema validation, **"Smart Chunking,"** and automatic Arabic text normalization (removing Tatweel/Diacritics).

### ğŸ§  Smart Memory
Features an **"Infinite Context"** mechanism that summarizes conversation history dynamically to maintain long-term context without exhausting tokens.

---

## ğŸ“Š Benchmark Results (v3.0)

Tested against a ground-truth dataset for *Jawazat* and *Muroor* regulations on NVIDIA A100.

| Metric | Score | Status |
| :--- | :--- | :--- |
| **Semantic Accuracy** | **91.50%** | âœ… Excellent |
| **Avg. Latency** | **2.08 sec** | âš¡ Real-time |
| **Dialect Understanding** | **High** | ğŸ‡¸ğŸ‡¦ Native |

---

## ğŸ› ï¸ Tech Stack

### Infrastructure
* **Language:** Python 3.9
* **Hardware:** NVIDIA A100 (80GB/40GB), CUDA 12.x

### Models
* **LLM:** `ALLaM-AI/ALLaM-7B-Instruct-preview`
* **Embedding:** `BAAI/bge-m3`
* **ASR:** `openai/whisper-large-v3`

### Tools
* **Orchestration:** LangChain (v0.3), Transformers (v4.38+)
* **Database:** FAISS (GPU-Accelerated Vector Store)
* **UI:** Gradio 3.50.2 (Custom MOI Theme & RTL Support)

---

## ğŸ“‚ Project Structure

```text
MOI_Universal_Assistant/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ model_loader.py   # Singleton Model Manager (LLM/ASR/Embeddings) on A100
â”‚   â”œâ”€â”€ rag_pipeline.py   # RAG Logic, RRF Merge, Memory Summarization
â”‚   â””â”€â”€ vector_store.py   # FAISS Index Management & Recovery
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ingestion.py      # ETL Pipeline (CSV -> Documents)
â”‚   â”œâ”€â”€ preprocessor.py   # Text Cleaning & Sector Mapping
â”‚   â”œâ”€â”€ schema.py         # Strict Validation Rules
â”‚   â”œâ”€â”€ Data_Master/      # High-level Service CSVs
â”‚   â””â”€â”€ Data_chunks/      # Detailed Procedure CSVs
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py            # Gradio Application Logic
â”‚   â””â”€â”€ theme.py          # CSS Styling & HTML Headers
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py         # Rotational Logging System
â”‚   â”œâ”€â”€ tts.py            # Text-to-Speech with File Management
â”‚   â””â”€â”€ text_utils.py     # Advanced Arabic Normalization (NLP)
â”œâ”€â”€ config.py             # Central Configuration (Hyperparameters)
â””â”€â”€ main.py               # Application Entry Point
```
## âš¡ Quick Start

### 1. Prerequisites
* **Hardware:** NVIDIA GPU (A100 Recommended).
* **Auth:** Hugging Face Token (required for ALLaM model access).

### 2. Installation
Install dependencies (skips `flash-attn` build if needed):
```bash
pip install -r requirements.txt
```
### 3. Setup Environment
Export your Hugging Face token:
```bash
export HF_TOKEN=your_hf_token_here
```
### 4. Run System
The system handles data ingestion and model warmup automatically.

```Bash

python main.py
```
Access the UI at:
``` URL
http://localhost:7860
```

### âš ï¸ Troubleshooting
* **HF_TOKEN Error:** If the app crashes on startup, ensure your Hugging Face token has specific permissions to access `ALLaM-AI/ALLaM-7B-Instruct-preview`.
* **OOM (Out of Memory):** If running on a smaller GPU, try reducing `CHUNK_SIZE` in `config.py` or enabling `load_in_8bit` (requires `bitsandbytes`).
* **Flash Attention:** For maximum speed on A100, ensure `flash-attn` is installed. The system will fallback to standard attention if missing.

---

## ğŸ“„ License
Developed for KAUST course - 2026

**Version:** 3.0
**Last Updated:** 2026
